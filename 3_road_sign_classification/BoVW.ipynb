{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: modified dataset already created\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import preprocessing\n",
    "\n",
    "\n",
    "current_folder = Path()\n",
    "dataset_folder = current_folder / \"dataset\"\n",
    "images_folder = dataset_folder / \"images\"\n",
    "models_folder = current_folder / \"models\"\n",
    "logs_folder = current_folder / \"logs\"\n",
    "\n",
    "X_train, X_test, y_train, y_test = preprocessing.get_dataset()\n",
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom imblearn.over_sampling import SMOTE\\n\\nX_flat = np.reshape(X_train, (X_train.shape[0], int(np.product(X_train.shape) / X_train.shape[0])))\\n\\nsm = SMOTE(n_jobs=-1, random_state=42)\\nX_train_os, y_train_os = sm.fit_resample(X_flat, y_train)\\n\\nX_train_os_rs = np.reshape(X_train_os, tuple([X_train_os.shape[0]]) + X_train.shape[1:])\\n\\nX_train = X_train_os_rs\\ny_train = y_train_os\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_flat = np.reshape(X_train, (X_train.shape[0], int(np.product(X_train.shape) / X_train.shape[0])))\n",
    "\n",
    "sm = SMOTE(n_jobs=-1, random_state=42)\n",
    "X_train_os, y_train_os = sm.fit_resample(X_flat, y_train)\n",
    "\n",
    "X_train_os_rs = np.reshape(X_train_os, tuple([X_train_os.shape[0]]) + X_train.shape[1:])\n",
    "\n",
    "X_train = X_train_os_rs\n",
    "y_train = y_train_os\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['crosswalk', 'speedlimit', 'stop', 'trafficlight'], dtype='<U12'),\n",
       " array([160, 626,  74, 135], dtype=int64))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# One hot encoding\\nlabel_enc = sklearn.preprocessing.LabelEncoder()\\ny_train_raw = y_train\\ny_test_raw = y_test\\ny_train = label_enc.fit_transform(y_train)\\ny_test = label_enc.transform(y_test)\\none_hot = sklearn.preprocessing.OneHotEncoder(sparse=False)\\ny_train = one_hot.fit_transform(y_train.reshape(-1, 1))\\ny_test = one_hot.transform(y_test.reshape(-1, 1))\\n\\nX_train, X_valid, y_train, y_valid = train_test_split(\\n    X_train, y_train, test_size=0.25, random_state=54\\n)\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# One hot encoding\n",
    "label_enc = sklearn.preprocessing.LabelEncoder()\n",
    "y_train_raw = y_train\n",
    "y_test_raw = y_test\n",
    "y_train = label_enc.fit_transform(y_train)\n",
    "y_test = label_enc.transform(y_test)\n",
    "one_hot = sklearn.preprocessing.OneHotEncoder(sparse=False)\n",
    "y_train = one_hot.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test = one_hot.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train, y_train, test_size=0.25, random_state=54\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import skimage\n",
    "import numpy as np\n",
    "\n",
    "def extract_features(X_train, y_train):\n",
    "    sift_vectors = {}\n",
    "    for el in set(y_train):\n",
    "        sift_vectors[el] = []\n",
    "\n",
    "    descriptor_list = []\n",
    "    sift = cv2.SIFT_create()\n",
    "    #brisk = cv2.BRISK_create(30)\n",
    "\n",
    "    for label, image in zip(y_train, X_train):\n",
    "        img = skimage.img_as_ubyte(image)\n",
    "        kp, des = sift.detectAndCompute(img, None)\n",
    "        #kp, des = sift.detectAndCompute(image, None)\n",
    "        if des is None:\n",
    "            continue\n",
    "\n",
    "        descriptor_list.extend(des)\n",
    "        sift_vectors[label].append(des)\n",
    "\n",
    "    return [descriptor_list, sift_vectors]\n",
    "\n",
    "descriptor_list, all_bovw_feature = extract_features(X_train, y_train)\n",
    "_, test_bovw_feature = extract_features(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def kmeans(k, descriptor_list):\n",
    "    kmeans = KMeans(n_clusters=k, n_init=10)\n",
    "    kmeans.fit(descriptor_list)\n",
    "    visual_words = kmeans.cluster_centers_\n",
    "    return visual_words\n",
    "\n",
    "visual_words = kmeans(150, descriptor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "def find_index(instance, main_list):\n",
    "    min_dist = 10e50\n",
    "    min_idx = -1\n",
    "    for idx, el in enumerate(main_list):\n",
    "        dist = distance.euclidean(instance, el)\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            min_idx = idx\n",
    "\n",
    "    return min_idx\n",
    "\n",
    "def image_class(all_bovw, centers):\n",
    "    dict_feature = {}\n",
    "    for key, value in all_bovw.items():\n",
    "        category = []\n",
    "        for img_feat_descriptors in value:\n",
    "            histogram = np.zeros(len(centers))\n",
    "            for each_feature in img_feat_descriptors:\n",
    "                ind = find_index(each_feature, centers)\n",
    "                histogram[ind] += 1\n",
    "            category.append(histogram)\n",
    "        dict_feature[key] = category\n",
    "    return dict_feature\n",
    "\n",
    "# Creates histograms for train data\n",
    "bovw_train = image_class(all_bovw_feature, visual_words)\n",
    "# Creates histograms for test data\n",
    "bovw_test = image_class(test_bovw_feature, visual_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(images, tests):\n",
    "    num_test = 0\n",
    "    correct_predict = 0\n",
    "    class_based = {}\n",
    "\n",
    "    for test_key, test_val in tests.items():\n",
    "        class_based[test_key] = [0, 0]  # [correct, all]\n",
    "        for tst in test_val:\n",
    "            predict_start = 0\n",
    "            # print(test_key)\n",
    "            minimum = 0\n",
    "            key = \"a\"  # predicted\n",
    "            for train_key, train_val in images.items():\n",
    "                for train in train_val:\n",
    "                    if predict_start == 0:\n",
    "                        minimum = distance.euclidean(tst, train)\n",
    "                        # minimum = L1_dist(tst,train)\n",
    "                        key = train_key\n",
    "                        predict_start += 1\n",
    "                    else:\n",
    "                        dist = distance.euclidean(tst, train)\n",
    "                        # dist = L1_dist(tst,train)\n",
    "                        if dist < minimum:\n",
    "                            minimum = dist\n",
    "                            key = train_key\n",
    "\n",
    "            if test_key == key:\n",
    "                correct_predict += 1\n",
    "                class_based[test_key][0] += 1\n",
    "            num_test += 1\n",
    "            class_based[test_key][1] += 1\n",
    "            # print(minimum)\n",
    "    return [num_test, correct_predict, class_based]\n",
    "\n",
    "# Evaluate per class\n",
    "results_bowl = knn(bovw_train, bovw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: %90.36144578313254\n",
      "-------------------------\n",
      "Class based accuracies:\n",
      "trafficlight: % 65.714\n",
      "speedlimit: % 94.904\n",
      "stop: % 94.118\n",
      "crosswalk: % 92.500\n"
     ]
    }
   ],
   "source": [
    "def accuracy(results):\n",
    "    avg_accuracy = (results[1] / results[0]) * 100\n",
    "    print(\"Average accuracy: %\" + str(avg_accuracy))\n",
    "    print(\"-------------------------\")\n",
    "    print(\"Class based accuracies:\")\n",
    "    for key, value in results[2].items():\n",
    "        acc = (value[0] / value[1]) * 100\n",
    "        print(f\"{key}: % {acc:.3f}\")\n",
    "\n",
    "accuracy(results_bowl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20228/1527174530.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mY_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# one-hot to index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mY_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m print(\n\u001b[0;32m      4\u001b[0m     sklearn.metrics.classification_report(\n\u001b[0;32m      5\u001b[0m         \u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabel_enc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "Y_pred = np.argmax(y_pred, axis=1)  # one-hot to index\n",
    "Y_test = np.argmax(y_test, axis=1)\n",
    "print(\n",
    "    sklearn.metrics.classification_report(\n",
    "        , Y_pred, target_names=label_enc.classes_\n",
    "    )\n",
    ")\n",
    "\n",
    "# Evaluate general\n",
    "test_results = model.evaluate(X_test, y_test)  # loss and metrics\n",
    "print(f\"Test Data - Loss: {test_results[0]:.3f}, Metrics: {test_results[1:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b687fa8d2924685de702f443b26f867ddb7d5902d1e0ebebe4df1af7eecd6ed1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('ml': virtualenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
