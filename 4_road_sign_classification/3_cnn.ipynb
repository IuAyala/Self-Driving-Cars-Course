{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: modified dataset already created\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import preprocessing\n",
    "\n",
    "\n",
    "current_folder = Path()\n",
    "dataset_folder = current_folder / \"dataset\"\n",
    "images_folder = dataset_folder / \"images\"\n",
    "models_folder = current_folder / \"models\"\n",
    "logs_folder = current_folder / \"logs\"\n",
    "\n",
    "X_train, X_test, y_train, y_test = preprocessing.get_dataset()\n",
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['crosswalk', 'speedlimit', 'stop', 'trafficlight'], dtype='<U12'),\n",
       " array([118, 543,  71,  94]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_flat = np.reshape(X_train, (X_train.shape[0], int(np.product(X_train.shape) / X_train.shape[0])))\n",
    "\n",
    "sm = SMOTE(n_jobs=-1, random_state=42)\n",
    "X_train_os, y_train_os = sm.fit_resample(X_flat, y_train)\n",
    "\n",
    "X_train_os_rs = np.reshape(X_train_os, tuple([X_train_os.shape[0]]) + X_train.shape[1:])\n",
    "\n",
    "X_train = X_train_os_rs\n",
    "y_train = y_train_os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['crosswalk', 'speedlimit', 'stop', 'trafficlight'], dtype='<U12'),\n",
       " array([543, 543, 543, 543]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding\n",
    "label_enc = sklearn.preprocessing.LabelEncoder()\n",
    "y_train = label_enc.fit_transform(y_train)\n",
    "y_test = label_enc.transform(y_test)\n",
    "one_hot = sklearn.preprocessing.OneHotEncoder(sparse=False)\n",
    "y_train = one_hot.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test = one_hot.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train, y_train, test_size=0.25, random_state=54\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25046041 0.24248005 0.25659914 0.25046041]\n",
      "[0.01780233 0.09146716 0.00736648 0.01043585]\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(y_train, axis=0) / len(y_train))\n",
    "print(np.sum(y_test, axis=0) / len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-24 12:32:41.092944: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-24 12:32:41.148241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-24 12:32:41.148634: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-24 12:32:41.150293: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-24 12:32:41.151614: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-24 12:32:41.151837: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-24 12:32:41.152114: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-24 12:32:41.899114: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-24 12:32:41.899452: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-24 12:32:41.899615: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-24 12:32:41.899759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4274 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-24 12:32:42.213981: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 195480000 exceeds 10% of free system memory.\n",
      "2021-12-24 12:32:42.355022: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 195480000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-24 12:32:44.977451: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8300\n",
      "2021-12-24 12:32:47.140058: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - ETA: 0s - loss: 1.3195 - accuracy: 0.3757"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-24 12:32:49.903219: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 65160000 exceeds 10% of free system memory.\n",
      "2021-12-24 12:32:49.970590: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 65160000 exceeds 10% of free system memory.\n",
      "2021-12-24 12:32:50.897229: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 35389440 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 10s 88ms/step - loss: 1.3195 - accuracy: 0.3757 - val_loss: 1.2756 - val_accuracy: 0.5985\n",
      "Epoch 2/500\n",
      "51/51 [==============================] - 3s 55ms/step - loss: 0.9253 - accuracy: 0.6538 - val_loss: 0.6973 - val_accuracy: 0.7864\n",
      "Epoch 3/500\n",
      "51/51 [==============================] - 2s 43ms/step - loss: 0.4034 - accuracy: 0.8686 - val_loss: 0.6021 - val_accuracy: 0.8379\n",
      "Epoch 4/500\n",
      "51/51 [==============================] - 2s 44ms/step - loss: 0.3051 - accuracy: 0.9128 - val_loss: 0.0925 - val_accuracy: 0.9853\n",
      "Epoch 5/500\n",
      "51/51 [==============================] - 2s 41ms/step - loss: 0.2335 - accuracy: 0.9380 - val_loss: 0.1154 - val_accuracy: 0.9779\n",
      "Epoch 6/500\n",
      "51/51 [==============================] - 2s 41ms/step - loss: 0.1409 - accuracy: 0.9656 - val_loss: 0.0883 - val_accuracy: 0.9853\n",
      "Epoch 7/500\n",
      "51/51 [==============================] - 2s 44ms/step - loss: 0.0787 - accuracy: 0.9828 - val_loss: 0.0506 - val_accuracy: 0.9890\n",
      "Epoch 8/500\n",
      "51/51 [==============================] - 2s 42ms/step - loss: 0.0765 - accuracy: 0.9797 - val_loss: 0.0751 - val_accuracy: 0.9816\n",
      "Epoch 9/500\n",
      "51/51 [==============================] - 2s 41ms/step - loss: 0.0637 - accuracy: 0.9828 - val_loss: 0.0361 - val_accuracy: 0.9926\n",
      "Epoch 10/500\n",
      "51/51 [==============================] - 2s 40ms/step - loss: 0.0638 - accuracy: 0.9822 - val_loss: 0.0500 - val_accuracy: 0.9908\n",
      "Epoch 11/500\n",
      "51/51 [==============================] - 2s 41ms/step - loss: 0.0500 - accuracy: 0.9853 - val_loss: 0.0316 - val_accuracy: 0.9926\n",
      "Epoch 12/500\n",
      "51/51 [==============================] - 2s 45ms/step - loss: 0.0372 - accuracy: 0.9908 - val_loss: 0.0325 - val_accuracy: 0.9926\n",
      "Epoch 13/500\n",
      "51/51 [==============================] - 2s 42ms/step - loss: 0.0232 - accuracy: 0.9926 - val_loss: 0.0380 - val_accuracy: 0.9926\n",
      "Epoch 14/500\n",
      "51/51 [==============================] - 2s 42ms/step - loss: 0.0190 - accuracy: 0.9957 - val_loss: 0.0257 - val_accuracy: 0.9963\n",
      "Epoch 15/500\n",
      "51/51 [==============================] - 2s 43ms/step - loss: 0.0148 - accuracy: 0.9945 - val_loss: 0.0249 - val_accuracy: 0.9963\n",
      "Epoch 16/500\n",
      "51/51 [==============================] - 2s 42ms/step - loss: 0.0141 - accuracy: 0.9957 - val_loss: 0.0332 - val_accuracy: 0.9926\n",
      "Epoch 17/500\n",
      "51/51 [==============================] - 2s 40ms/step - loss: 0.0300 - accuracy: 0.9908 - val_loss: 0.0262 - val_accuracy: 0.9945\n",
      "Epoch 18/500\n",
      "51/51 [==============================] - 2s 44ms/step - loss: 0.0237 - accuracy: 0.9945 - val_loss: 0.0372 - val_accuracy: 0.9926\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from functools import partial\n",
    "\n",
    "# Keras model\n",
    "DefaultConv2D = partial(\n",
    "    keras.layers.Conv2D, kernel_size=3, activation=\"relu\", padding=\"SAME\"\n",
    ")\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        DefaultConv2D(\n",
    "            filters=64, kernel_size=7, input_shape=list(X_train[0].shape)\n",
    "        ),  # was 28, 28, 1\n",
    "        keras.layers.MaxPooling2D(pool_size=2),\n",
    "        DefaultConv2D(filters=128),\n",
    "        DefaultConv2D(filters=128),\n",
    "        keras.layers.MaxPooling2D(pool_size=2),\n",
    "        DefaultConv2D(filters=256),\n",
    "        DefaultConv2D(filters=256),\n",
    "        keras.layers.MaxPooling2D(pool_size=2),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(units=128, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.2),  # lower less regularization\n",
    "        keras.layers.Dense(units=64, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(units=4, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=\"sgd\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# loss\n",
    "# sparse_categorical_crossentropy used for sparse labels (target class index)\n",
    "# categorial_cross_entropy would yield a one-hot vector (only one positive label)\n",
    "# mean_squared_error for regression\n",
    "\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=logs_folder,\n",
    "    histogram_freq=1,\n",
    ")\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=3,\n",
    "    restore_best_weights=False,\n",
    ")\n",
    "\n",
    "print(\"Start training\")\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=500,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[tensorboard_cb, early_stopping_cb],\n",
    ")\n",
    "\n",
    "# Save model\n",
    "os.makedirs(models_folder, exist_ok=True)\n",
    "model.save(models_folder / \"model1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   crosswalk       0.90      0.97      0.93        29\n",
      "  speedlimit       0.99      0.98      0.99       149\n",
      "        stop       1.00      1.00      1.00        12\n",
      "trafficlight       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.97       207\n",
      "   macro avg       0.94      0.96      0.95       207\n",
      "weighted avg       0.97      0.97      0.97       207\n",
      "\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.1214 - accuracy: 0.9710\n",
      "Test Data - Loss: 0.121, Metrics: [0.9710144996643066]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate per class\n",
    "y_pred = model.predict(X_test)\n",
    "Y_pred = np.argmax(y_pred, axis=1)  # one-hot to index\n",
    "Y_test = np.argmax(y_test, axis=1)\n",
    "print(\n",
    "    sklearn.metrics.classification_report(\n",
    "        Y_test, Y_pred, target_names=label_enc.classes_\n",
    "    )\n",
    ")\n",
    "\n",
    "# Evaluate general\n",
    "test_results = model.evaluate(X_test, y_test)  # loss and metrics\n",
    "print(f\"Test Data - Loss: {test_results[0]:.3f}, Metrics: {test_results[1:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b687fa8d2924685de702f443b26f867ddb7d5902d1e0ebebe4df1af7eecd6ed1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('ml': virtualenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
